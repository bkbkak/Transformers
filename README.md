# Transformer-IWSLT17: åŸºäº PyTorch çš„ Transformer å¾·è‹±ç¿»è¯‘é¡¹ç›®

## ç®€ä»‹ (Introduction)

æœ¬é¡¹ç›®åŸºäº **PyTorch** å®ç°äº†ç»å…¸çš„ **Transformer** æ¶æ„ï¼ˆVaswani et al., 2017ï¼‰ï¼Œç”¨äºè§£å†³**æœºå™¨ç¿»è¯‘ ($\text{Machine Translation, MT}$)** ä»»åŠ¡ã€‚æˆ‘ä»¬ä½¿ç”¨ **IWSLT 2017 å¾·è¯­-è‹±è¯­ ($\text{De-En}$)** ç¿»è¯‘æ•°æ®é›†è¿›è¡Œè®­ç»ƒå’Œè¯„ä¼°ã€‚

è¯¥é¡¹ç›®åŒ…å«äº†æ•°æ®é¢„å¤„ç†ã€æ¨¡å‹è®­ç»ƒã€éªŒè¯ã€æµ‹è¯•ä»¥åŠ BLEU åˆ†æ•°è¯„ä¼°çš„å…¨å¥—æµç¨‹ï¼Œæ—¨åœ¨æä¾›ä¸€ä¸ªæ¸…æ™°ã€é«˜æ•ˆã€å¯å¤ç°çš„ Transformer æ¨¡å‹åŸºçº¿å®ç°ã€‚

## âœ¨ ä¸»è¦ç‰¹æ€§ (Features)

* **å…¨åŠŸèƒ½ Transformer:** å®ç°å®Œæ•´çš„ç¼–ç å™¨-è§£ç å™¨æ¶æ„ã€å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶ ($\text{MHA}$) å’Œä½ç½®ç¼–ç  ($\text{Positional Encoding}$)ã€‚
* **å­è¯åŒ– ($\text{Subword}$):** ä½¿ç”¨ $\text{SentencePiece}$ è¿›è¡Œ $\text{BPE}$ å­è¯åŒ–ï¼Œæœ‰æ•ˆå¤„ç†å¼€æ”¾è¯æ±‡é—®é¢˜ã€‚
* **å¤šç¯å¢ƒæ”¯æŒ:** æä¾› $\text{Shell}$ è„šæœ¬ (`.sh`) æ”¯æŒåŸºçº¿è®­ç»ƒå’Œæ¶ˆèå®éªŒã€‚
* **æ¨¡å‹æ£€æŸ¥ç‚¹:** è®­ç»ƒè¿‡ç¨‹ä¸­è‡ªåŠ¨ä¿å­˜æ¨¡å‹æ£€æŸ¥ç‚¹å’ŒæŸå¤±æ›²çº¿ã€‚
* **BLEU è¯„ä¼°:** ä½¿ç”¨æ ‡å‡† $\text{BLEU}$ åˆ†æ•°ä½œä¸ºè¯„ä»·æŒ‡æ ‡ï¼Œè¿›è¡Œå®šé‡æ€§èƒ½åˆ†æã€‚

## ğŸ› ï¸ æŠ€æœ¯æ ˆä¸ä¾èµ– (Technology Stack & Dependencies)

* **è¯­è¨€:** Python 3.8+
* **æ ¸å¿ƒæ¡†æ¶:** PyTorch (æ¨è 1.10.x åŠä»¥ä¸Š)
* **å…³é”®ä¾èµ–:** NumPy, SentencePiece

### å®‰è£…ä¾èµ–

å»ºè®®åˆ›å»ºä¸€ä¸ªè™šæ‹Ÿç¯å¢ƒå¹¶å®‰è£…æ‰€éœ€çš„åº“ï¼š

```bash
# åˆ›å»ºå¹¶æ¿€æ´» conda ç¯å¢ƒ (æ¨è)
conda create -n transformer_mt python=3.9
conda activate transformer_mt

# å®‰è£… PyTorch å’Œå…¶ä»–ä¾èµ–
pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple




### ğŸ“¦ æ•°æ®å‡†å¤‡ (Dataset Preparation)

æœ¬é¡¹ç›®ä½¿ç”¨ IWSLT17 è‹±å¾·ç¿»è¯‘æ•°æ®é›†ã€‚
# å¯¼èˆªåˆ° dataset ç›®å½•
cd dataset

# è§£å‹ zip æ–‡ä»¶åˆ°ä¸Šä¸€çº§çš„ data ç›®å½•
# å‡è®¾ unzip å‘½ä»¤å¯ç”¨ï¼Œä¸”è§£å‹åä¼šäº§ç”Ÿ data/en-de-data ç»“æ„
data/en-de-data/
â”œâ”€â”€ train.tags.en-de.en
â”œâ”€â”€ train.tags.en-de.de
â”œâ”€â”€ IWSLT17.TED.dev2010.en-de.en.xml
â”œâ”€â”€ IWSLT17.TED.dev2010.en-de.de.xml
â”œâ”€â”€ IWSLT17.TED.tst2010.en-de.en.xml
â””â”€â”€ IWSLT17.TED.tst2010.en-de.de.xml

unzip iwslt17_en_de.zip -d ../data



# è¿”å›é¡¹ç›®æ ¹ç›®å½•
cd ..


###  æ•°æ®é¢„å¤„ç†
preprocessed/
â”œâ”€â”€ train_data.pt
â”œâ”€â”€ dev_data.pt
â”œâ”€â”€ test_data.pt
â”œâ”€â”€ spm_bpe_8k.model
â”œâ”€â”€ spm_bpe_8k.vocab
â””â”€â”€ vocab_info.json
#  è¿è¡Œdata.py 
python src/data.py

###é¡¹ç›®ç»“æ„ (Project Structure)
Transformer/
â”œâ”€â”€ data/                # åŸå§‹æ•°æ®
â”œâ”€â”€ preprocessed/         # é¢„å¤„ç†ç»“æœ (tensor, vocab)
â”œâ”€â”€ src/                  # æºä»£ç 
â”‚   â”œâ”€â”€ model.py          # Transformer æ¨¡å‹å®šä¹‰
â”‚   â”œâ”€â”€ train.py          # è®­ç»ƒä¸»å¾ªç¯
â”‚   â”œâ”€â”€ eval.py           # BLEU è¯„ä¼°
â”‚   â”œâ”€â”€ data.py           # æ•°æ®åŠ è½½ä¸é¢„å¤„ç†
â”‚   â””â”€â”€ utils.py          # å·¥å…·å‡½æ•°
â”œâ”€â”€ scripts/              # å®éªŒè„šæœ¬
â”‚   â”œâ”€â”€ run_baseline.sh
â”‚   â”œâ”€â”€ run_ablations.sh
â”‚   â”œâ”€â”€ eval_baseline.sh
â”‚   â””â”€â”€ eval_ablations.sh
â”œâ”€â”€ results/              # æ¨¡å‹è¾“å‡ºä¸æ—¥å¿—
â”‚   â”œâ”€â”€ checkpoints/
â”‚   â”œâ”€â”€ *.json
â”‚   â”œâ”€â”€ *.txt
â”‚   â””â”€â”€ *.png
â””â”€â”€ README.md



#è¿è¡ŒåŸºçº¿æ¨¡å‹
bash scripts/run_baseline.sh
#è¿è¡Œæ¶ˆèå®éªŒ
bash scripts/run_ablations.sh
#è¿è¡Œè¯„ä¼°å‡½æ•°åŸºçº¿æ¨¡å‹
bash scripts/eval_baseline.sh
# è¯„ä¼°ç»“æœå°†ä¿å­˜åœ¨ ./results/ ç›®å½•ä¸‹çš„ .json å’Œ .txt æ–‡ä»¶ä¸­
#è¯„ä»·æ‰€æœ‰æ¶ˆèå®éªŒçš„æ¨¡å‹
bash scripts/eval_ablations.sh
